#!/usr/bin/env python3
"""
üß† Multi-Timeframe LSTM Forex Predictor
Professional ensemble LSTM model with 5 years training on H4, H1, 15m, 1D
"""

import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
import warnings
import json
import argparse
from datetime import datetime, timedelta
import os
import pickle
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

warnings.filterwarnings('ignore')
tf.get_logger().setLevel('ERROR')

# Create models directory
os.makedirs(os.path.join(os.path.dirname(__file__), 'saved_models'), exist_ok=True)

class MultiTimeframeForexLSTM:
    def __init__(self, timeframes=['1D', '4h', '1h', '15m'], lookback_period=60, epochs=100, batch_size=64):
        """
        Professional multi-timeframe LSTM ensemble for forex prediction

        Args:
            timeframes: List of timeframes to train models for
            lookback_period: Number of previous periods for sequences
            epochs: Training epochs
            batch_size: Batch size for training
        """
        self.timeframes = timeframes
        self.lookback_period = lookback_period
        self.epochs = epochs
        self.batch_size = batch_size

        # Scalers and models for each timeframe
        self.scalers = {tf: MinMaxScaler(feature_range=(0, 1)) for tf in timeframes}
        self.models = {tf: None for tf in timeframes}
        self.model_trained = {tf: False for tf in timeframes}

        # Model directory
        self.model_dir = os.path.join(os.path.dirname(__file__), 'saved_models')
        os.makedirs(self.model_dir, exist_ok=True)

        # Threading lock for model operations
        self.lock = threading.Lock()

    def get_forex_data(self, pair, timeframe="1D", period="5y"):
        """
        Get historical forex data for specific timeframe
        Downloads 5 years of data for professional training
        """
        try:
            # Convert forex pair to yfinance format
            symbol_map = {
                "EURUSD": "EURUSD=X", "GBPUSD": "GBPUSD=X", "USDJPY": "USDJPY=X",
                "USDCHF": "USDCHF=X", "AUDUSD": "AUDUSD=X", "USDCAD": "USDCAD=X",
                "NZDUSD": "NZDUSD=X", "EURGBP": "EURGBP=X", "EURJPY": "EURJPY=X"
            }
            symbol = symbol_map.get(pair, f"{pair}=X")

            # Map timeframes to yfinance intervals
            interval_map = {
                '1D': '1d', '4h': '1h', '1h': '1h', '15m': '15m',
                '1d': '1d', '4H': '1h', '1H': '1h'
            }
            interval = interval_map.get(timeframe, '1d')

            print(f"üì• Downloading {pair} data for {timeframe} timeframe (5 years)...")

            # Download 5 years of data
            data = yf.download(symbol, period=period, interval=interval, progress=False)

            if data.empty:
                print(f"‚ùå No data available for {pair} on {timeframe}")
                return None

            # For 4H timeframe, resample 1H data to 4H
            if timeframe in ['4h', '4H']:
                data = data.resample('4H').agg({
                    'Open': 'first', 'High': 'max', 'Low': 'min',
                    'Close': 'last', 'Volume': 'sum'
                }).dropna()

            # Clean data
            data = data.dropna()

            if len(data) < 200:
                print(f"‚ùå Insufficient data for {pair} on {timeframe}: {len(data)} bars")
                return None

            # Add comprehensive technical indicators
            self._add_technical_indicators(data)

            print(f"‚úÖ Downloaded {len(data)} bars for {pair} {timeframe}")
            return data.dropna()

        except Exception as e:
            print(f"‚ùå Error downloading {pair} data: {e}")
            return None

    def _add_technical_indicators(self, data):
        """
        Add comprehensive technical indicators for LSTM features
        """
        try:
            # Moving Averages
            data.loc[:, 'SMA_5'] = data['Close'].rolling(window=5).mean()
            data.loc[:, 'SMA_10'] = data['Close'].rolling(window=10).mean()
            data.loc[:, 'SMA_20'] = data['Close'].rolling(window=20).mean()
            data.loc[:, 'SMA_50'] = data['Close'].rolling(window=50).mean()
            data.loc[:, 'EMA_12'] = data['Close'].ewm(span=12).mean()
            data.loc[:, 'EMA_26'] = data['Close'].ewm(span=26).mean()

            # MACD
            data.loc[:, 'MACD'] = data['EMA_12'] - data['EMA_26']
            data.loc[:, 'MACD_Signal'] = data['MACD'].ewm(span=9).mean()
            data.loc[:, 'MACD_Histogram'] = data['MACD'] - data['MACD_Signal']

            # RSI
            delta = data['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            data.loc[:, 'RSI'] = 100 - (100 / (1 + rs))

            # Bollinger Bands
            bb_period = 20
            bb_middle = data['Close'].rolling(window=bb_period).mean()
            bb_std = data['Close'].rolling(window=bb_period).std()
            data.loc[:, 'BB_Upper'] = bb_middle + (bb_std * 2)
            data.loc[:, 'BB_Lower'] = bb_middle - (bb_std * 2)
            data.loc[:, 'BB_Middle'] = bb_middle

            # ATR (Average True Range)
            tr1 = data['High'] - data['Low']
            tr2 = abs(data['High'] - data['Close'].shift())
            tr3 = abs(data['Low'] - data['Close'].shift())
            data.loc[:, 'ATR'] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1).rolling(window=14).mean()

            # Volatility measures
            data.loc[:, 'Volatility_20'] = data['Close'].rolling(window=20).std()
            data.loc[:, 'Volatility_5'] = data['Close'].rolling(window=5).std()

            # Price changes and momentum
            data.loc[:, 'Price_Change'] = data['Close'].pct_change()
            data.loc[:, 'Price_Change_5'] = data['Close'].pct_change(5)
            data.loc[:, 'Momentum_10'] = data['Close'] / data['Close'].shift(10) - 1

            # Volume indicators (synthetic for forex)
            data.loc[:, 'Volume_SMA'] = data['Close'].rolling(window=5).std() * 1000000
            data.loc[:, 'Volume_Ratio'] = data['Volume_SMA'] / data['Volume_SMA'].rolling(window=20).mean()

            # Day of week
            data.loc[:, 'DayOfWeek'] = data.index.dayofweek
            data.loc[:, 'DOW_Sin'] = np.sin(2 * np.pi * data['DayOfWeek'] / 7)
            data.loc[:, 'DOW_Cos'] = np.cos(2 * np.pi * data['DayOfWeek'] / 7)

        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Error adding technical indicators: {e}")
            # Add minimal indicators
            data.loc[:, 'SMA_20'] = data['Close'].rolling(window=20).mean()
            data.loc[:, 'RSI'] = 50  # Default RSI
            data.loc[:, 'Volatility_20'] = data['Close'].rolling(window=20).std()

    def prepare_lstm_data(self, data, timeframe):
        """
        Prepare data for LSTM training with comprehensive features
        """
        # Core OHLCV features
        core_features = ['Open', 'High', 'Low', 'Close']

        # Technical indicator features
        tech_features = [
            'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'EMA_12', 'EMA_26',
            'MACD', 'MACD_Signal', 'MACD_Histogram', 'RSI',
            'BB_Width', 'BB_Position', 'ATR', 'Volatility_20', 'Volatility_5',
            'Price_Change', 'Price_Change_5', 'Momentum_10', 'Volume_Ratio'
        ]

        # Time-based features (for intraday timeframes)
        time_features = []
        if timeframe in ['1h', '4h', '15m']:
            time_features = ['Hour_Sin', 'Hour_Cos', 'DOW_Sin', 'DOW_Cos']
        else:
            time_features = ['DOW_Sin', 'DOW_Cos']

        # Combine all features
        all_features = core_features + tech_features + time_features

        # Use only available features
        available_features = [f for f in all_features if f in data.columns]

        print(f"üìä Using {len(available_features)} features for {timeframe}: {available_features[:5]}...")

        feature_data = data[available_features].values

        # Scale the data using timeframe-specific scaler
        scaled_data = self.scalers[timeframe].fit_transform(feature_data)

        # Create sequences for LSTM
        X, y = [], []
        for i in range(self.lookback_period, len(scaled_data)):
            X.append(scaled_data[i-self.lookback_period:i])
            y.append(scaled_data[i, 3])  # Predict Close price (index 3 in OHLC)

        return np.array(X), np.array(y), available_features

    def build_advanced_lstm_model(self, input_shape, timeframe):
        """
        Build advanced LSTM architecture optimized for different timeframes
        """
        # Adjust architecture based on timeframe
        if timeframe in ['15m']:
            # More layers for short-term patterns
            lstm_units = [128, 64, 32]
            dropout_rate = 0.3
        elif timeframe in ['1h', '4h']:
            # Balanced architecture
            lstm_units = [100, 50, 25]
            dropout_rate = 0.25
        else:  # 1D
            # Simpler for daily data
            lstm_units = [64, 32]
            dropout_rate = 0.2

        model = Sequential()

        # First LSTM layer
        model.add(LSTM(units=lstm_units[0], return_sequences=True, input_shape=input_shape))
        model.add(BatchNormalization())
        model.add(Dropout(dropout_rate))

        # Additional LSTM layers
        for i, units in enumerate(lstm_units[1:]):
            return_seq = i < len(lstm_units) - 2
            model.add(LSTM(units=units, return_sequences=return_seq))
            model.add(BatchNormalization())
            model.add(Dropout(dropout_rate))

        # Dense layers
        model.add(Dense(units=50, activation='relu'))
        model.add(Dropout(dropout_rate * 0.5))
        model.add(Dense(units=25, activation='relu'))
        model.add(Dense(units=1))

        # Custom optimizer with learning rate scheduling
        optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)

        model.compile(
            optimizer=optimizer,
            loss='huber',  # More robust to outliers
            metrics=['mae', 'mse']
        )

        return model

    def train_timeframe_model(self, pair, timeframe):
        """
        Train LSTM model for specific timeframe with 5 years of data
        """
        print(f"üß† Training {timeframe} LSTM model for {pair} (5 years data)...")

        # Check if model already exists and is trained
        model_path = os.path.join(self.model_dir, f"{pair}_{timeframe}_model.h5")
        scaler_path = os.path.join(self.model_dir, f"{pair}_{timeframe}_scaler.pkl")

        if os.path.exists(model_path) and os.path.exists(scaler_path):
            print(f"üìÅ Loading existing {timeframe} model for {pair}...")
            try:
                with self.lock:
                    self.models[timeframe] = load_model(model_path)
                    with open(scaler_path, 'rb') as f:
                        self.scalers[timeframe] = pickle.load(f)
                    self.model_trained[timeframe] = True
                print(f"‚úÖ Loaded existing {timeframe} model")
                return True
            except Exception as e:
                print(f"‚ö†Ô∏è Error loading model, retraining: {e}")

        # Get 5 years of historical data
        data = self.get_forex_data(pair, timeframe, period="5y")
        if data is None:
            return False

        print(f"üìä Processing {len(data)} bars of {timeframe} data")

        # Prepare LSTM data
        X, y, features = self.prepare_lstm_data(data, timeframe)

        if len(X) < 200:
            print(f"‚ùå Not enough data for training {timeframe}: {len(X)} sequences")
            return False

        # Advanced train/validation/test split
        train_size = int(len(X) * 0.7)
        val_size = int(len(X) * 0.15)

        X_train = X[:train_size]
        y_train = y[:train_size]
        X_val = X[train_size:train_size + val_size]
        y_val = y[train_size:train_size + val_size]
        X_test = X[train_size + val_size:]
        y_test = y[train_size + val_size:]

        print(f"üéØ {timeframe} - Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")

        # Build model
        with self.lock:
            self.models[timeframe] = self.build_advanced_lstm_model(
                (X_train.shape[1], X_train.shape[2]), timeframe
            )

        # Advanced callbacks
        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=15,
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=7,
                min_lr=1e-6,
                verbose=1
            ),
            ModelCheckpoint(
                model_path,
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            )
        ]

        # Train model
        print(f"üöÄ Training {timeframe} LSTM model...")
        history = self.models[timeframe].fit(
            X_train, y_train,
            epochs=self.epochs,
            batch_size=self.batch_size,
            validation_data=(X_val, y_val),
            callbacks=callbacks,
            verbose=1
        )

        # Evaluate model
        if len(X_test) > 0:
            test_loss = self.models[timeframe].evaluate(X_test, y_test, verbose=0)
            print(f"üìä {timeframe} Test Loss: {test_loss[0]:.6f}, MAE: {test_loss[1]:.6f}")

        # Save scaler
        with open(scaler_path, 'wb') as f:
            pickle.dump(self.scalers[timeframe], f)

        print(f"‚úÖ {timeframe} model training completed")
        self.model_trained[timeframe] = True
        return True

    def train_all_timeframes(self, pair):
        """
        Train models for all timeframes in parallel
        """
        print(f"üöÄ Training ensemble models for {pair} on {len(self.timeframes)} timeframes...")

        # Use ThreadPoolExecutor for parallel training
        with ThreadPoolExecutor(max_workers=2) as executor:
            futures = {
                executor.submit(self.train_timeframe_model, pair, tf): tf
                for tf in self.timeframes
            }

            results = {}
            for future in as_completed(futures):
                tf = futures[future]
                try:
                    results[tf] = future.result()
                    if results[tf]:
                        print(f"‚úÖ {tf} training completed")
                    else:
                        print(f"‚ùå {tf} training failed")
                except Exception as e:
                    print(f"‚ùå {tf} training error: {e}")
                    results[tf] = False

        return results

    def predict_ensemble(self, pair, periods=5):
        """
        Generate ensemble predictions from all timeframes
        """
        print(f"üîÆ Generating ensemble predictions for {pair}...")

        timeframe_predictions = {}
        timeframe_confidence = {}

        for timeframe in self.timeframes:
            if not self.model_trained[timeframe]:
                print(f"‚ö†Ô∏è {timeframe} model not trained, skipping")
                continue

            try:
                predictions, confidence = self._predict_timeframe(pair, timeframe, periods)
                if predictions is not None:
                    timeframe_predictions[timeframe] = predictions
                    timeframe_confidence[timeframe] = confidence
                    print(f"‚úÖ {timeframe} predictions: {predictions[-1]:.5f} (conf: {confidence:.1f}%)")

            except Exception as e:
                print(f"‚ùå {timeframe} prediction error: {e}")
                continue

        if not timeframe_predictions:
            return None, None

        # Weighted ensemble based on timeframe importance and confidence
        weights = {
            '1D': 0.4,   # Long-term trend
            '4h': 0.3,   # Medium-term momentum
            '1h': 0.2,   # Short-term direction
            '15m': 0.1   # Very short-term
        }

        # Calculate weighted average
        weighted_predictions = []
        total_confidence = 0

        for i in range(periods):
            weighted_sum = 0
            weight_sum = 0

            for tf, predictions in timeframe_predictions.items():
                if i < len(predictions):
                    weight = weights.get(tf, 0.25) * (timeframe_confidence[tf] / 100)
                    weighted_sum += predictions[i] * weight
                    weight_sum += weight

            if weight_sum > 0:
                weighted_predictions.append(weighted_sum / weight_sum)
            else:
                weighted_predictions.append(None)

        # Calculate ensemble confidence
        for tf, conf in timeframe_confidence.items():
            total_confidence += conf * weights.get(tf, 0.25)

        return weighted_predictions, total_confidence

    def _predict_timeframe(self, pair, timeframe, periods):
        """
        Generate predictions for specific timeframe
        """
        # Get recent data
        data = self.get_forex_data(pair, timeframe, period="6m")
        if data is None:
            return None, 0

        # Prepare data
        X, _, _ = self.prepare_lstm_data(data, timeframe)
        if len(X) < 1:
            return None, 0

        # Get last sequence
        last_sequence = X[-1].reshape(1, X.shape[1], X.shape[2])

        # Predict next values
        predictions = []
        current_sequence = last_sequence.copy()
        confidence_scores = []

        for _ in range(periods):
            pred = self.models[timeframe].predict(current_sequence, verbose=0)
            predictions.append(pred[0, 0])

            # Simple confidence based on prediction stability
            confidence_scores.append(min(95, 60 + abs(pred[0, 0]) * 1000))

            # Update sequence for next prediction
            new_row = current_sequence[0, -1].copy()
            new_row[3] = pred[0, 0]  # Update close price (index 3)

            # Shift sequence and add new prediction
            current_sequence = np.roll(current_sequence, -1, axis=1)
            current_sequence[0, -1] = new_row

        # Inverse transform predictions
        dummy_features = np.zeros((len(predictions), self.scalers[timeframe].n_features_in_))
        dummy_features[:, 3] = predictions  # Close price at index 3

        predicted_prices = self.scalers[timeframe].inverse_transform(dummy_features)[:, 3]
        avg_confidence = np.mean(confidence_scores)

        return predicted_prices.tolist(), avg_confidence

    def analyze_pair(self, pair):
        """
        Complete multi-timeframe ensemble analysis
        """
        print(f"\nüß† Multi-Timeframe LSTM Analysis for {pair}")
        print("=" * 60)

        # Train all timeframes if needed
        training_results = self.train_all_timeframes(pair)
        trained_count = sum(1 for success in training_results.values() if success)

        if trained_count == 0:
            return {
                'error': True,
                'message': 'Failed to train any timeframe models',
                'pair': pair
            }

        print(f"‚úÖ Successfully trained {trained_count}/{len(self.timeframes)} models")

        # Get current data (use daily for current price)
        current_data = self.get_forex_data(pair, "1D", period="1m")
        if current_data is None:
            return None

        current_price = float(current_data['Close'].iloc[-1])

        # Generate ensemble predictions
        predictions, ensemble_confidence = self.predict_ensemble(pair, periods=5)

        if predictions is None:
            return {
                'error': True,
                'message': 'Failed to generate predictions',
                'pair': pair
            }

        # Calculate trend and signals
        final_prediction = predictions[-1] if predictions[-1] is not None else current_price
        price_change = (final_prediction - current_price) / current_price * 100

        # Advanced recommendation logic
        if price_change > 0.3:
            action = "BUY"
            confidence = min(95, max(65, ensemble_confidence))
        elif price_change < -0.3:
            action = "SELL"
            confidence = min(95, max(65, ensemble_confidence))
        else:
            action = "HOLD"
            confidence = min(80, max(50, ensemble_confidence * 0.8))

        # Enhanced technical analysis
        recent_data = current_data.tail(50)
        support = float(recent_data['Low'].min())
        resistance = float(recent_data['High'].max())
        current_rsi = float(current_data['RSI'].iloc[-1]) if 'RSI' in current_data else 50
        sma_20 = float(current_data['SMA_20'].iloc[-1]) if 'SMA_20' in current_data else current_price

        # Timeframe analysis summary
        timeframe_summary = []
        for tf in self.timeframes:
            if training_results.get(tf, False):
                timeframe_summary.append(f"{tf} model trained with 5y data")

        return {
            'pair': pair,
            'current_price': round(current_price, 5),
            'predicted_prices': [round(p, 5) if p is not None else None for p in predictions],
            'price_change_percent': round(price_change, 2),
            'recommendation': {
                'action': action,
                'confidence': round(confidence, 1),
                'reasons': [
                    f"Ensemble LSTM predicts {price_change:+.2f}% change",
                    f"Multi-timeframe confidence: {confidence:.1f}%",
                    f"Based on {trained_count} timeframes with 5-year training",
                    "Advanced ensemble neural network analysis"
                ]
            },
            'technical': {
                'support': round(support, 5),
                'resistance': round(resistance, 5),
                'current_rsi': round(current_rsi, 1),
                'sma_20': round(sma_20, 5)
            },
            'model_info': {
                'model_type': 'Multi-Timeframe LSTM Ensemble',
                'training_data': '5 years historical data',
                'timeframes': ', '.join(self.timeframes),
                'features': '20+ technical indicators per timeframe',
                'architecture': 'Advanced LSTM + BatchNorm + Ensemble',
                'framework': 'TensorFlow/Keras with parallel training',
                'trained_models': f"{trained_count}/{len(self.timeframes)} timeframes",
                'ensemble_method': 'Weighted average with confidence scoring'
            },
            'timeframe_details': timeframe_summary,
            'status': 'professional',
            'timestamp': datetime.now().isoformat()
        }

def main():
    parser = argparse.ArgumentParser(description='Multi-Timeframe LSTM Forex Predictor')
    parser.add_argument('--pair', type=str, default='EURUSD', help='Forex pair to analyze')
    parser.add_argument('--web', type=bool, default=False, help='Output JSON for web')
    parser.add_argument('--train-only', action='store_true', help='Only train models')
    parser.add_argument('--timeframes', nargs='+', default=['1D', '4h', '1h', '15m'],
                       help='Timeframes to train/analyze')

    args = parser.parse_args()

    # Initialize multi-timeframe predictor
    predictor = MultiTimeframeForexLSTM(
        timeframes=args.timeframes,
        lookback_period=60,
        epochs=50,  # Reduced for faster training
        batch_size=64
    )

    if args.train_only:
        # Train all timeframes
        print(f"üöÄ Training {len(args.timeframes)} timeframe models for {args.pair}...")
        results = predictor.train_all_timeframes(args.pair)

        trained = sum(1 for success in results.values() if success)
        print(f"\n‚úÖ Training completed: {trained}/{len(args.timeframes)} models successful")

        for tf, success in results.items():
            status = "‚úÖ" if success else "‚ùå"
            print(f"{status} {tf}: {'Success' if success else 'Failed'}")
        return

    # Full ensemble analysis
    print(f"üß† Starting professional multi-timeframe analysis for {args.pair}...")
    result = predictor.analyze_pair(args.pair)

    if args.web:
        # Output JSON for web interface
        if result:
            print(json.dumps(result, indent=2))
        else:
            print(json.dumps({'error': 'Failed to analyze pair'}, indent=2))
    else:
        # Enhanced console output
        if result and not result.get('error'):
            print(f"\n{'='*60}")
            print(f"üí± {result['pair']} PROFESSIONAL ENSEMBLE ANALYSIS")
            print(f"{'='*60}")
            print(f"üìä Current Price: {result['current_price']}")
            print(f"üéØ 5-Period Predictions: {' ‚Üí '.join([str(p) for p in result['predicted_prices'] if p])}")
            print(f"üìà Expected Change: {result['price_change_percent']:+.2f}%")
            print(f"ü§ñ Recommendation: {result['recommendation']['action']} ({result['recommendation']['confidence']:.1f}%)")
            print(f"\nüîç Analysis Details:")
            for reason in result['recommendation']['reasons']:
                print(f"  ‚Ä¢ {reason}")
            print(f"\nüß† Model Architecture: {result['model_info']['model_type']}")
            print(f"üìö Training Data: {result['model_info']['training_data']}")
            print(f"‚è∞ Timeframes: {result['model_info']['timeframes']}")
            print(f"üéØ Models Trained: {result['model_info']['trained_models']}")
            print(f"\nüìà Technical Levels:")
            print(f"  Support: {result['technical']['support']}")
            print(f"  Resistance: {result['technical']['resistance']}")
            print(f"  RSI: {result['technical']['current_rsi']}")
            print(f"  SMA20: {result['technical']['sma_20']}")
        else:
            error_msg = result.get('message', 'Unknown error') if result else 'Analysis failed'
            print(f"‚ùå {error_msg}")

if __name__ == "__main__":
    main()